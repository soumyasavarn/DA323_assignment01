{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10978954,"sourceType":"datasetVersion","datasetId":6832149}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Use Case Demonstration of LexiVerse, idea is to train a small generative model (from scratch using a fraction of my dataset) using LSTM to show that this dataset can be used for fine tuning LLMs or any GPTs ","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport random\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Embedding\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.utils import to_categorical\nimport re\nimport gc\n\n# Step 1: Load and Preprocess Data in Batches\n# I am selecting only 200 words per file for a faster training\ndef load_and_preprocess_data(path, words_per_file=200):\n    texts = []\n    for file in os.listdir(path):\n        if file.endswith('.txt'):\n            with open(os.path.join(path, file), 'r', encoding='utf-8') as f:\n                text = f.read().lower()\n                # Basic text cleaning\n                text = re.sub(r'[^\\w\\s]', '', text)\n                # Take only the first 500 words\n                words = text.split()[:words_per_file]\n                texts.extend(words)\n    return ' '.join(texts)\n\n# Load all text files, taking only the first 200 words from each\ndata_path = '/kaggle/input/lexi-verse/'\ncorpus = load_and_preprocess_data(data_path)\n\n# Tokenize the text\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts([corpus])\ntotal_words = len(tokenizer.word_index) + 1\n\ninput_sequences = []\nfor line in corpus.split('\\n'):\n    token_list = tokenizer.texts_to_sequences([line])[0]\n    for i in range(1, len(token_list)):\n        n_gram_sequence = token_list[:i+1]\n        input_sequences.append(n_gram_sequence)\n    gc.collect()\n\nmax_sequence_len = max([len(x) for x in input_sequences])\ninput_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n\nX, y = input_sequences[:,:-1], input_sequences[:,-1]\ny = to_categorical(y, num_classes=total_words)\n\nmodel = Sequential()\nmodel.add(Embedding(total_words, 200, input_length=max_sequence_len-1))\nmodel.add(LSTM(200, return_sequences=False))  \nmodel.add(Dense(total_words, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T09:39:50.564462Z","iopub.execute_input":"2025-03-10T09:39:50.564791Z","iopub.status.idle":"2025-03-10T09:39:51.420256Z","shell.execute_reply.started":"2025-03-10T09:39:50.564760Z","shell.execute_reply":"2025-03-10T09:39:51.419545Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"print (total_words)\nprint (X)\nprint (y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T09:58:03.283023Z","iopub.execute_input":"2025-03-10T09:58:03.283337Z","iopub.status.idle":"2025-03-10T09:58:03.289494Z","shell.execute_reply.started":"2025-03-10T09:58:03.283315Z","shell.execute_reply":"2025-03-10T09:58:03.288690Z"}},"outputs":[{"name":"stdout","text":"2146\n[[   0    0    0 ...    0    0    2]\n [   0    0    0 ...    0    2  665]\n [   0    0    0 ...    2  665    4]\n ...\n [   0    0    2 ... 2142 2143 2144]\n [   0    2  665 ... 2143 2144 2145]\n [   2  665    4 ... 2144 2145  664]]\n[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 1.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"# Training the Model in Batches\nbatch_size = 64\ndef batch_generator(X, y, batch_size):\n    while True:\n        for i in range(0, len(X), batch_size):\n            yield X[i:i+batch_size], y[i:i+batch_size]\n\nmodel.fit(batch_generator(X, y, batch_size), steps_per_epoch=len(X)//batch_size, epochs=60, verbose=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T09:39:58.498352Z","iopub.execute_input":"2025-03-10T09:39:58.498689Z","iopub.status.idle":"2025-03-10T09:56:15.777282Z","shell.execute_reply.started":"2025-03-10T09:39:58.498663Z","shell.execute_reply":"2025-03-10T09:56:15.776494Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 265ms/step - accuracy: 0.0130 - loss: 7.6667\nEpoch 2/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 265ms/step - accuracy: 0.0419 - loss: 7.5287\nEpoch 3/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 263ms/step - accuracy: 0.0066 - loss: 7.6381\nEpoch 4/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 264ms/step - accuracy: 0.0145 - loss: 7.5681\nEpoch 5/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 264ms/step - accuracy: 0.0188 - loss: 7.4075\nEpoch 6/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 264ms/step - accuracy: 0.0190 - loss: 7.2574\nEpoch 7/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 264ms/step - accuracy: 0.0175 - loss: 7.1415\nEpoch 8/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 264ms/step - accuracy: 0.0181 - loss: 7.2453\nEpoch 9/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 264ms/step - accuracy: 0.0274 - loss: 7.0839\nEpoch 10/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 262ms/step - accuracy: 0.0321 - loss: 6.9164\nEpoch 11/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 262ms/step - accuracy: 0.0438 - loss: 6.7032\nEpoch 12/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 264ms/step - accuracy: 0.0392 - loss: 6.5601\nEpoch 13/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 264ms/step - accuracy: 0.0448 - loss: 6.3747\nEpoch 14/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 261ms/step - accuracy: 0.0453 - loss: 6.1880\nEpoch 15/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 260ms/step - accuracy: 0.0500 - loss: 6.0397\nEpoch 16/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 260ms/step - accuracy: 0.0530 - loss: 5.9162\nEpoch 17/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 260ms/step - accuracy: 0.0569 - loss: 5.6925\nEpoch 18/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 260ms/step - accuracy: 0.0659 - loss: 5.4823\nEpoch 19/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 260ms/step - accuracy: 0.0693 - loss: 5.4323\nEpoch 20/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 262ms/step - accuracy: 0.0810 - loss: 5.2175\nEpoch 21/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 265ms/step - accuracy: 0.1021 - loss: 4.9804\nEpoch 22/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 265ms/step - accuracy: 0.1052 - loss: 4.8388\nEpoch 23/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 265ms/step - accuracy: 0.1226 - loss: 4.6552\nEpoch 24/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 265ms/step - accuracy: 0.1540 - loss: 4.4844\nEpoch 25/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 264ms/step - accuracy: 0.1746 - loss: 4.2939\nEpoch 26/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 263ms/step - accuracy: 0.2289 - loss: 3.9962\nEpoch 27/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 263ms/step - accuracy: 0.2998 - loss: 3.6558\nEpoch 28/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 262ms/step - accuracy: 0.3575 - loss: 3.4020\nEpoch 29/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 263ms/step - accuracy: 0.3587 - loss: 3.3322\nEpoch 30/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 263ms/step - accuracy: 0.4198 - loss: 2.9595\nEpoch 31/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 262ms/step - accuracy: 0.5127 - loss: 2.6775\nEpoch 32/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 262ms/step - accuracy: 0.5341 - loss: 2.4441\nEpoch 33/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 263ms/step - accuracy: 0.5627 - loss: 2.2595\nEpoch 34/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 262ms/step - accuracy: 0.5861 - loss: 2.0687\nEpoch 35/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 262ms/step - accuracy: 0.5808 - loss: 1.9687\nEpoch 36/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 263ms/step - accuracy: 0.6342 - loss: 1.7555\nEpoch 37/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 263ms/step - accuracy: 0.6952 - loss: 1.5724\nEpoch 38/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 263ms/step - accuracy: 0.7253 - loss: 1.4395\nEpoch 39/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 262ms/step - accuracy: 0.7703 - loss: 1.2404\nEpoch 40/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 263ms/step - accuracy: 0.7834 - loss: 1.1425\nEpoch 41/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 263ms/step - accuracy: 0.8083 - loss: 1.0622\nEpoch 42/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 262ms/step - accuracy: 0.8461 - loss: 0.9454\nEpoch 43/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 262ms/step - accuracy: 0.8485 - loss: 0.9044\nEpoch 44/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 262ms/step - accuracy: 0.8657 - loss: 0.8371\nEpoch 45/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 262ms/step - accuracy: 0.8926 - loss: 0.7752\nEpoch 46/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 263ms/step - accuracy: 0.9172 - loss: 0.6741\nEpoch 47/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 263ms/step - accuracy: 0.9308 - loss: 0.6057\nEpoch 48/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 262ms/step - accuracy: 0.9398 - loss: 0.5744\nEpoch 49/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 261ms/step - accuracy: 0.9463 - loss: 0.5136\nEpoch 50/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 261ms/step - accuracy: 0.9565 - loss: 0.4747\nEpoch 51/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 260ms/step - accuracy: 0.9551 - loss: 0.4358\nEpoch 52/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 260ms/step - accuracy: 0.9683 - loss: 0.3984\nEpoch 53/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 260ms/step - accuracy: 0.9698 - loss: 0.3763\nEpoch 54/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 261ms/step - accuracy: 0.9728 - loss: 0.3711\nEpoch 55/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 260ms/step - accuracy: 0.9780 - loss: 0.3412\nEpoch 56/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 261ms/step - accuracy: 0.9789 - loss: 0.2899\nEpoch 57/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 261ms/step - accuracy: 0.9843 - loss: 0.2518\nEpoch 58/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 260ms/step - accuracy: 0.9842 - loss: 0.2462\nEpoch 59/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 261ms/step - accuracy: 0.9768 - loss: 0.2620\nEpoch 60/60\n\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 263ms/step - accuracy: 0.9817 - loss: 0.2434\n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7f798741e470>"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"# Step 4: Text Generation Function\ndef generate_text(seed_text, next_words, model, max_sequence_len):\n    for _ in range(next_words):\n        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n        predicted = np.argmax(model.predict(token_list), axis=-1)\n        output_word = \"\"\n        for word, index in tokenizer.word_index.items():\n            if index == predicted:\n                output_word = word\n                break\n        seed_text += \" \" + output_word\n    return seed_text\n\n# Demonstration\nprint(\"Generating text from different seeds:\")\nseeds = [\n    \n    \"The environment is crucial because\",\n    \"Health is important because\"\n]\n\nfor seed in seeds:\n    generated_text = generate_text(seed, 6, model, max_sequence_len)\n    print(f\"\\nSeed: {seed}\")\n    print(f\"Generated: {generated_text}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T10:01:28.764648Z","iopub.execute_input":"2025-03-10T10:01:28.764966Z","iopub.status.idle":"2025-03-10T10:01:30.043191Z","shell.execute_reply.started":"2025-03-10T10:01:28.764940Z","shell.execute_reply":"2025-03-10T10:01:30.042440Z"}},"outputs":[{"name":"stdout","text":"Generating text from different seeds:\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n\nSeed: The environment is crucial because\nGenerated: The environment is crucial because self decade ago says already destination\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n\nSeed: Health is important because\nGenerated: Health is important because httpswwwhealthcom health trusted empathetic health wellness\n","output_type":"stream"}],"execution_count":56},{"cell_type":"markdown","source":"## Could be improved using Word2Vec or GLOVE and also due to preprocessing our dataset do not ober grammar of English language. \n## httpswwwhealthcom is printed due to multiple links as metadata in our file on which our model is trained","metadata":{}},{"cell_type":"markdown","source":"## This code runs only a sampled version of the dataset, still performs decent enough without any hyperparameter tuning. So, the full dataset can be used for Fine Tuning any SOTA GPTs.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}